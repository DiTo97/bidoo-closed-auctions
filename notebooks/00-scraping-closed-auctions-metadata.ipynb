{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import re\n",
        "import subprocess\n",
        "import typing\n",
        "\n",
        "\n",
        "def is_in_jupyter_notebook() -> bool:\n",
        "    \"\"\"It checks whether a Jupyter notebook is being run\"\"\"\n",
        "    try:\n",
        "        get_ipython\n",
        "        return True\n",
        "    except NameError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def is_on_gcolab() -> bool:\n",
        "    \"\"\"It checks whether a Jupyter notebook is being run on Google Colab\"\"\"\n",
        "    if not is_in_jupyter_notebook():\n",
        "        return False\n",
        "\n",
        "    return \"google.colab\" in str(get_ipython())\n",
        "\n",
        "\n",
        "def is_ubuntu_20_04() -> bool:\n",
        "    import lsb_release\n",
        "    metadata = lsb_release.get_os_release()\n",
        "\n",
        "    distro  = metadata[\"ID\"].lower()\n",
        "    release = metadata[\"RELEASE\"]\n",
        "\n",
        "    return distro == \"ubuntu\" and release == \"20.04\"\n",
        "\n",
        "\n",
        "def setup_ubuntu_20_04() -> None:\n",
        "    \"\"\"It sets up a Ubuntu 20.04 container with the Chromium browser\n",
        "\n",
        "    For more information, see \n",
        "    https://github.com/googlecolab/colabtools/issues/3347#issuecomment-1387453484\n",
        "    \"\"\"\n",
        "    # It adds debian buster\n",
        "    EOF_debian_buster = \"\"\"\\\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "\"\"\"\n",
        "    !echo \"$EOF_debian_buster\" > /etc/apt/sources.list.d/debian.list\n",
        "\n",
        "    # It adds keys\n",
        "    !apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "    !apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "    !apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "    !apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "    !apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "    !apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "    # It adds the debian repo for chromium* packages only\n",
        "    # Note the double-blank lines between entries\n",
        "    EOF_chromium_pref = \"\"\"\\\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "\"\"\"\n",
        "    !echo \"$EOF_chromium_pref\" > /etc/apt/preferences.d/chromium.pref\n",
        "\n",
        "    # It installs the packages\n",
        "    !apt-get update\n",
        "    !apt-get install -y chromium chromium-driver\n",
        "    !apt-get install -y xvfb\n",
        "\n",
        "\n",
        "def setup_requirements() -> None:\n",
        "    requirements = \" \".join([\n",
        "        \"PyVirtualDisplay==3.0\",  # To run a virtual display\n",
        "        \"undetected-chromedriver==3.2.1\",\n",
        "    ])\n",
        "\n",
        "    !python3 -m pip install --upgrade pip\n",
        "    !python3 -m pip install --upgrade $requirements\n",
        "\n",
        "\n",
        "def get_module_path(module: str) -> typing.Optional[pathlib.Path]:\n",
        "    \"\"\"It gets the absolute path of a module, or None if not installed\"\"\"\n",
        "    response = subprocess.run(\n",
        "        [\"python3\", \"-m\", \"pip\", \"show\", module], \n",
        "        capture_output=True\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response.check_returncode()\n",
        "    except subprocess.CalledProcessError:\n",
        "        return None\n",
        "\n",
        "    stdout = response.stdout.decode()\n",
        "\n",
        "    try:\n",
        "        RE_abspath = \"\\nLocation: (?P<abspath>.*)\\n\"\n",
        "\n",
        "        matches = re.search(RE_abspath, stdout)\n",
        "        abspath = matches.group(\"abspath\")\n",
        "    except AttributeError:\n",
        "        return None\n",
        "\n",
        "    dist_packages = pathlib.Path(abspath).resolve()\n",
        "    return dist_packages / module\n",
        "\n",
        "\n",
        "def patch_undetected_chromedriver() -> None:\n",
        "    \"\"\"It forces `undetected-chromedriver` to run the Chromium webdriver\n",
        "\n",
        "    For more information, see \n",
        "    https://github.com/ultrafunkamsterdam/undetected-chromedriver/issues/108#issuecomment-1170269377\n",
        "    \"\"\"\n",
        "    chromedriver_filename = \"chromedriver_linux64.zip\"\n",
        "\n",
        "    src_chromedriver_filepath = ROOT / chromedriver_filename\n",
        "    dst_chromedriver_filepath = pathlib.Path(\"/tmp\") / chromedriver_filename\n",
        "\n",
        "    !zip -j \"$src_chromedriver_filepath\" /usr/bin/chromedriver\n",
        "\n",
        "    module = \"undetected_chromedriver\"\n",
        "    module_path = get_module_path(module)\n",
        "\n",
        "    patcher_filepath = module_path / \"patcher.py\"\n",
        "\n",
        "    with patcher_filepath.open(\"rt\") as f:\n",
        "        contents = f.read()\n",
        "\n",
        "    src = f\"'file://{src_chromedriver_filepath}'\"\n",
        "    dst = f\"'{dst_chromedriver_filepath}'\"\n",
        "\n",
        "    # It is forced to use the local webdriver\n",
        "    contents = contents.replace(\n",
        "        f\"return urlretrieve(u)[0]\",\n",
        "        f\"return urlretrieve({src}, filename={dst})[0]\"\n",
        "    )\n",
        "\n",
        "    with patcher_filepath.open(\"wt\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "\n",
        "def setup_container() -> None:\n",
        "    \"\"\"It sets up the container which is being run\"\"\"\n",
        "    if is_ubuntu_20_04():\n",
        "        setup_ubuntu_20_04()\n",
        "\n",
        "    setup_requirements()\n",
        "    patch_undetected_chromedriver()\n",
        "\n",
        "\n",
        "assert is_on_gcolab(), \"It seems you are not on Google Colab\"\n",
        "\n",
        "\n",
        "ROOT = pathlib.Path().resolve()\n",
        "anchor = ROOT / \"anchor.txt\"\n",
        "\n",
        "\n",
        "if not anchor.exists():\n",
        "    setup_container()\n",
        "    anchor.touch()"
      ],
      "metadata": {
        "id": "RaTcrY_91Ceb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import time\n",
        "from dataclasses import dataclass, asdict\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import bs4\n",
        "import pandas as pd\n",
        "import pytz\n",
        "import pyvirtualdisplay\n",
        "import undetected_chromedriver.v2 as uc\n",
        "from bs4 import BeautifulSoup as BS\n",
        "from joblib import delayed, Parallel\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.ui import WebDriverWait"
      ],
      "metadata": {
        "id": "WXiZMCCs5Zwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CET = pytz.timezone(\"CET\")"
      ],
      "metadata": {
        "id": "eck07Q5pfmyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Metadata:\n",
        "    \"\"\"A class that maps the metadata of a Bidoo closed auction\"\"\"\n",
        "    auction: int\n",
        "    auction_src: str\n",
        "    product_image: str\n",
        "    product: str\n",
        "    timestamp: int\n",
        "    winner_username: str"
      ],
      "metadata": {
        "id": "0-u9RESJ2s6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def current_localized_date() -> datetime.date:\n",
        "    \"\"\"It gets the current date localized in Bidoo's timezone (CET)\"\"\"\n",
        "    localized = datetime.now().astimezone(CET)\n",
        "    localized = localized.date()\n",
        "\n",
        "    return localized"
      ],
      "metadata": {
        "id": "1JbZ7A4p5lCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def htmlparse_metadata(referer: str, auction: bs4.Tag) -> typing.Optional[Metadata]:\n",
        "    metadata = None\n",
        "\n",
        "    try:\n",
        "        timestamp_node = auction.find(\"abbr\", {\"data-utime\": True})\n",
        "        timestamp = int(timestamp_node[\"data-utime\"])\n",
        "\n",
        "        container = auction.find(class_=\"row\")\n",
        "\n",
        "        product_image_node = container.select_one(\"a.closed-auction-img > img\")\n",
        "        product_image = product_image_node[\"src\"]\n",
        "\n",
        "        product_node = container.select_one(\".media-heading > a\")\n",
        "        product = product_node.text\n",
        "\n",
        "        auction_src = product_node[\"href\"]\n",
        "        auction_src = f\"{referer}{auction_src}\"\n",
        "\n",
        "        auction = int(auction_src.split(\"_\")[-1])\n",
        "\n",
        "        winner_username_node = container.select_one(\".username > span\")\n",
        "        winner_username = winner_username_node.text\n",
        "\n",
        "        metadata = Metadata(\n",
        "            auction,\n",
        "            auction_src,\n",
        "            product_image,\n",
        "            product,\n",
        "            timestamp,\n",
        "            winner_username\n",
        "        )\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return metadata"
      ],
      "metadata": {
        "id": "9C8QREJeB0-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_metadata_by_date(\n",
        "    auctions: typing.List[Metadata], reference: datetime.date\n",
        ") -> typing.List[Metadata]:\n",
        "    same_date_1d_mask = [\n",
        "        datetime.fromtimestamp(metadata.timestamp, CET)\n",
        "        for metadata in auctions\n",
        "    ]\n",
        "\n",
        "    same_date_1d_mask = [\n",
        "        datetime_.date() == reference for datetime_ in same_date_1d_mask\n",
        "    ]\n",
        "\n",
        "    filtered = [\n",
        "        auction for idx, auction in enumerate(auctions) if same_date_1d_mask[idx]\n",
        "    ]\n",
        "\n",
        "    return filtered"
      ],
      "metadata": {
        "id": "7wwIQA9Xd2M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_closed_auctions_metadata(\n",
        "    endpoint: str, \n",
        "    referer: str,\n",
        "    timeout_secs: float, \n",
        "    webdriver: uc.Chrome,\n",
        "    **joblib_kwargs\n",
        ") -> typing.List[typing.Optional[Metadata]]:\n",
        "    webdriver.get(endpoint)\n",
        "\n",
        "    WebDriverWait(webdriver, timeout_secs).until(\n",
        "        EC.visibility_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"div.list.media.loading\")\n",
        "        )\n",
        "    )\n",
        "\n",
        "    soup = BS(webdriver.page_source, \"html.parser\")\n",
        "\n",
        "    auctions = soup.find_all(\"div\", class_=\"data_offset\")\n",
        "\n",
        "    auctions = Parallel(**joblib_kwargs)(\n",
        "        delayed(htmlparse_metadata)(referer, auction)\n",
        "        for auction in auctions\n",
        "    )\n",
        "\n",
        "    return auctions"
      ],
      "metadata": {
        "id": "CcslKIzvjbU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scraping_closed_auctions_metadata(\n",
        "    closed_auctions_endpoint: str,\n",
        "    output_location: pathlib.Path, \n",
        "    referer: str,\n",
        "    sleep_secs: float,\n",
        "    timeout_secs: float,\n",
        "    **joblib_kwargs\n",
        ") -> None:\n",
        "    shard_date = current_localized_date()\n",
        "    shard_date = shard_date - timedelta(days=1)  # It runs after midnight\n",
        "\n",
        "    shard_location = output_location / str(shard_date)\n",
        "\n",
        "    if not shard_location.exists():\n",
        "        shard_location.mkdir(parents=True)\n",
        "\n",
        "    base_endpoint = f\"{referer}/{closed_auctions_endpoint}\"\n",
        "\n",
        "    options = uc.ChromeOptions()\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    \n",
        "    with pyvirtualdisplay.Display(visible=0, size=(800, 600)) as _:\n",
        "        webdriver = uc.Chrome(options=options)\n",
        "\n",
        "        finished = False\n",
        "        page = 0\n",
        "\n",
        "        try:\n",
        "            while not finished:\n",
        "                page += 1\n",
        "                page_filepath = shard_location / f\"{page}.csv\"\n",
        "\n",
        "                endpoint = f\"{base_endpoint}?_={page}\"\n",
        "\n",
        "                if page_filepath.exists():\n",
        "                    continue\n",
        "\n",
        "                shard = scrape_closed_auctions_metadata(\n",
        "                    endpoint, referer, timeout_secs, webdriver, **joblib_kwargs\n",
        "                )\n",
        "\n",
        "                shard = [metadata for metadata in shard if metadata is not None]\n",
        "                shard_count = len(shard)\n",
        "\n",
        "                filtered = filter_metadata_by_date(shard, shard_date)\n",
        "    \n",
        "                if filtered:\n",
        "                    frame = pd.DataFrame([asdict(metadata) for metadata in finished])\n",
        "                    frame.to_csv(page_filepath, index=False)\n",
        "\n",
        "                finished = len(filtered) < shard_count\n",
        "\n",
        "                if finished:\n",
        "                    continue\n",
        "\n",
        "                time.sleep(sleep_secs)\n",
        "        finally:\n",
        "            webdriver.quit()"
      ],
      "metadata": {
        "id": "YrlTmRvl5sED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib_kwargs = {\n",
        "    \"backend\": \"threading\",\n",
        "    \"n_jobs\": -1\n",
        "}"
      ],
      "metadata": {
        "id": "p2HBW_R5BoE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"closed_auctions_endpoint\": \"closed_auctions.php\",\n",
        "    \"output_location\": ROOT / \"output\",\n",
        "    \"referer\": \"https://it.bidoo.com\",\n",
        "    \"sleep_secs\": 30.,\n",
        "    \"timeout_secs\": 30.,\n",
        "    **joblib_kwargs\n",
        "}"
      ],
      "metadata": {
        "id": "nnwQtSKU6AZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scraping_closed_auctions_metadata(**kwargs)"
      ],
      "metadata": {
        "id": "5MFjHVee5_d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0lVYEPQCENq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}